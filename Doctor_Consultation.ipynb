{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "We have all been in situation where we go to a doctor in emergency and find that the consultation fees are too high. As a data scientist we all should do better. What if you have data that records important details about a doctor and you get to build a model to predict the doctorâ€™s consulting fee.? This is the use case that let's you do that. \n",
    "\n",
    "Size of training set: 5961 records\n",
    "\n",
    "Size of test set: 1987 records\n",
    "\n",
    "\n",
    "FEATURES:\n",
    "\n",
    "Qualification: Qualification and degrees held by the doctor\n",
    "\n",
    "Experience: Experience of the doctor in number of years\n",
    "\n",
    "Rating: Rating given by patients\n",
    "\n",
    "Profile: Type of the doctor\n",
    "\n",
    "Miscellaneous_Info: Extra information about the doctor\n",
    "\n",
    "Fees: Fees charged by the doctor (Target Variable)\n",
    "\n",
    "Place: Area and the city where the doctor is located.\n",
    "\n",
    "\n",
    "Using the given features we have to build a model which can predict Doctor's Consultation Fees.\n",
    "\n",
    "As the Fees(target  variable) is continuous is nature we will follow Regression approach for this.\n",
    "\n",
    "Lets Begin....!!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Data Set into Dataframe\n",
    "doctor_train=pd.read_excel('Doctor_Train.xlsx')\n",
    "doctor_test=pd.read_excel('Doctor_Test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',None)\n",
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Training Dataset\n",
    "\n",
    "doctor_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Dataset Info\n",
    "\n",
    "doctor_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Shape\n",
    "\n",
    "doctor_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 5961 rows and 7 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Datatypes\n",
    "\n",
    "doctor_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from fees all are object type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Test Dataset\n",
    "\n",
    "doctor_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Null Values in Training Data\n",
    "\n",
    "doctor_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Null Values in Test Data\n",
    "doctor_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have Null values in Rating, Place and Miscelleneous Column in both dataset. We will fill these null values along with treating the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see there are columns like Qualification and Place which contains multiple information. Also Experience and Rating columns has string values because of which they are Object type. we will extract these values from these columns one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working on Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting with Experience Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking unique values and there counts\n",
    "\n",
    "doctor_train['Experience'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_train['Experience'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will remove string from the values and keep integer values only.Also we will convert datatype to int32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting string and assigning 0th index value back to column and converting to int32\n",
    "\n",
    "string1=doctor_train['Experience'].str.split()\n",
    "doctor_train['Experience']=string1.str[0]\n",
    "doctor_train['Experience']=doctor_train['Experience'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we correct rating column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting string and assigning 0th index value back to column.\n",
    "\n",
    "string3=doctor_train['Rating'].str.split('%')\n",
    "doctor_train['Rating']=string3.str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling NaN values with 0\n",
    "\n",
    "doctor_train['Rating'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to int32\n",
    "\n",
    "doctor_train['Rating']=doctor_train['Rating'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the string and store value for area and city in different columns\n",
    "\n",
    "string4=doctor_train['Place'].str.split(',')\n",
    "doctor_train['Area']=string4.str[0].replace(' ','')\n",
    "doctor_train['City']=string4.str[1].replace(' ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qualification Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We follow the same procedure of splitting and assigning vales to seperate columns.\n",
    "\n",
    "# We store the method of splitting in a variable\n",
    "\n",
    "train_split = doctor_train.Qualification.apply(lambda x: len(x.split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a function to create seperate columns according to the length given by train_split variable\n",
    "\n",
    "def qualif_column(data, col, col_num):\n",
    "    return data[col].str.split(',').str[col_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we pass Qualification column in the function \n",
    "\n",
    "# for training set\n",
    "for i in range(0,train_split.max()):\n",
    "    qualif = \"Qualification_\"+ str(i+1)\n",
    "    doctor_train[qualif] = qualif_column(doctor_train,'Qualification', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check our training dataset\n",
    "\n",
    "doctor_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset looks good. Max qualification for a doctor is 10.\n",
    "\n",
    "We perform same tasks for Test Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting with Expereince column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_test['Experience'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting string and assigning 0th index value back to column and converting to int32\n",
    "\n",
    "string11=doctor_test['Experience'].str.split()\n",
    "doctor_test['Experience']=string11.str[0]\n",
    "doctor_test['Experience']=doctor_test['Experience'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Rating column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting string and assigning 0th index value back to column.\n",
    "\n",
    "string33=doctor_test['Rating'].str.split('%')\n",
    "doctor_test['Rating']=string33.str[0]\n",
    "\n",
    "# Filling NaN values with 0\n",
    "\n",
    "doctor_test['Rating'].fillna(0,inplace=True)\n",
    "\n",
    "\n",
    "# Converting to int32\n",
    "\n",
    "doctor_test['Rating']=doctor_test['Rating'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Place column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the string and store value for area and city in different columns\n",
    "\n",
    "string44=doctor_test['Place'].str.split(',')\n",
    "doctor_test['Area']=string4.str[0].replace(' ','')\n",
    "doctor_test['City']=string4.str[1].replace(' ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Qualification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We follow the same procedure of splitting and assigning vales to seperate columns.\n",
    "\n",
    "# We store the method of splitting in a variable\n",
    "\n",
    "test_split = doctor_test.Qualification.apply(lambda x: len(x.split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a function to create seperate columns according to the length given by train_split variable\n",
    "\n",
    "def qualif_column(data, col, col_num):\n",
    "    return data[col].str.split(',').str[col_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we pass Qualification column in the function \n",
    "\n",
    "# for test set\n",
    "for i in range(0,test_split.max()):\n",
    "    qualif = \"Qualification_\"+ str(i+1)\n",
    "    doctor_test[qualif] = qualif_column(doctor_test,'Qualification', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking dataset\n",
    "\n",
    "doctor_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In test dataset we have maximum 17 qualifications for a doctor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check our features and there impact on Fees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(8,6))\n",
    "sns.countplot(x='Profile',data=doctor_train,ax=ax)\n",
    "plt.title('Profile Count')\n",
    "plt.xticks(rotation=35)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Record count for Dentist profile is highest. This could possible mean that people visit a doctor for dental issues more frequently than other problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(8,6))\n",
    "sns.countplot(x='City',data=doctor_train,ax=ax)\n",
    "plt.title('Cities')\n",
    "plt.xticks(rotation=35)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see more number of records from Bangalore, Mumbai and Delhi. We also observe an unusual entry named Sector 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check the relatioship with Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='Profile',y='Fees',kind='bar',data=doctor_train,ax=ax)\n",
    "plt.title('Impact of Profile on Fees')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENT Specialist and Dermatologist charge the highest fees followed by General and Homeopathy doctors. Ayurveda doctors charge the least. \n",
    "\n",
    "This could possibly mean that there isn't enough favouritism for Ayurveda as compare to Allopathy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='City',y='Fees',kind='bar',data=doctor_train,ax=ax)\n",
    "plt.title('City wise tally of Fees')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We observe high Fee trend in Tier-I cities with Delhi at top."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observing relation of numerical columns with Fees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experience vs Fees\n",
    "plt.title('Experience vs Fees')\n",
    "plt.xlabel('Experience')\n",
    "plt.ylabel('Fees')\n",
    "sns.scatterplot(doctor_train['Experience'],doctor_train['Fees'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,12))\n",
    "sns.barplot('Experience','Fees',data=doctor_train)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There isn't a positive relation of Experience with Fees. We cannot say more or less experience have effect on Fee value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Rating\n",
    "\n",
    "plt.figure(figsize=(15,12))\n",
    "sns.barplot('Rating','Fees',data=doctor_train)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rating vs Fees\n",
    "plt.title('Rating vs Fees')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Fees')\n",
    "sns.scatterplot(doctor_train['Rating'],doctor_train['Fees'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a bit of negative correlation with Fees but we do observe that higher Fee value has low ratings. This could be interpreted as the doctors who charge less gets higher ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We check  for null values again and also for any unusual entry in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will replace null values for Area and city with 'Unknown' and replace unusual entry in Training dataset.\n",
    "\n",
    "doctor_train['Area']=doctor_train['Area'].fillna('Unknown')\n",
    "doctor_train['City']=doctor_train['City'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_train['Area']=doctor_train['Area'].replace('e','Unknown')\n",
    "doctor_train['City']=doctor_train['City'].replace(' Sector 5',' Delhi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_test['Area']=doctor_test['Area'].fillna('Unknown')\n",
    "doctor_test['City']=doctor_test['City'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking Unique values in both dataset\n",
    "\n",
    "doctor_train['Area'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_train['City'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_test['City'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All entries looks good lets check null values again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will encode qualification columns with category codes.\n",
    "\n",
    "As test data has more values for qualification we will create a dictionary of unique values with codes and replace values in datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy of Test Dataset\n",
    "\n",
    "data=doctor_test.copy()\n",
    "data1=doctor_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting strings in Qualification column\n",
    "\n",
    "data['Qualification']=data['Qualification'].str.split(',')\n",
    "data1['Qualification']=data1['Qualification'].str.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching values in a seperate list\n",
    "\n",
    "data_train=[]\n",
    "for i in range(data.shape[0]):\n",
    "    for j in data['Qualification'][i]:\n",
    "        data_train.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test=[]\n",
    "for i in range(data1.shape[0]):\n",
    "    for j in data1['Qualification'][i]:\n",
    "        data_test.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final=data_train+data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting unique values only\n",
    "\n",
    "data1_unique=list(set(data_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe with unique values\n",
    "\n",
    "df=pd.DataFrame(data1_unique,columns=['Qualification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a column with category codes\n",
    "\n",
    "df['Code']=df.Qualification.astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Dataframe\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a dictionory with qualification and codes\n",
    "\n",
    "qualif_dict=dict(zip(df.Qualification,df.Code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualif_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing values of qualifications with codes in Training and test dataset\n",
    "\n",
    "# For Training\n",
    "\n",
    "for k in doctor_train.iloc[:,9:]:\n",
    "    doctor_train.replace({k:qualif_dict},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Test Dataset\n",
    "\n",
    "for z in doctor_test.iloc[:,8:]:\n",
    "    doctor_test.replace({z:qualif_dict},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will encode city and profile using One Hot Encoder in both Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Training Data\n",
    "\n",
    "doctor_train=pd.get_dummies(doctor_train,columns=['Profile','City'],prefix=['Profile','City'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Test data\n",
    "doctor_test=pd.get_dummies(doctor_test,columns=['Profile','City'],prefix=['Profile','City'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Area column with category codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=doctor_train['Area'].unique()\n",
    "df2=pd.DataFrame(df2,columns=['Area'])\n",
    "df2['Area_Code']=df2['Area'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Area and Area Code dictionory\n",
    "\n",
    "area_dict=dict(zip(df2.Area,df2.Area_Code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing Area values with Codes in Train Dataset\n",
    "\n",
    "doctor_train.replace({'Area':area_dict},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing Area values with Codes in Test Dataset\n",
    "\n",
    "doctor_test.replace({'Area':area_dict},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing NaN with -1 for difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Training\n",
    "\n",
    "for x in doctor_train.iloc[:,7:17]:\n",
    "    doctor_train[x]=doctor_train[x].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Test\n",
    "\n",
    "for x in doctor_test.iloc[:,6:23]:\n",
    "    doctor_test[x]=doctor_test[x].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Input and Target Variables from Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=doctor_train.drop(['Qualification','Place','Miscellaneous_Info','Fees'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=doctor_train['Fees']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns from Test Datset as well\n",
    "# As we see there are few rows which has qualifications extended till 17th column. Thus we will drop these columns.\n",
    "doctor_test.drop(['Qualification','Place','Miscellaneous_Info','Qualification_11','Qualification_12','Qualification_13','Qualification_14','Qualification_15','Qualification_16','Qualification_17'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,12))\n",
    "sns.distplot(x['Experience'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only treat Experience column for skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import power_transform\n",
    "x['Experience']=power_transform(x['Experience'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Test dataset\n",
    "\n",
    "doctor_test.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import power_transform\n",
    "doctor_test['Experience']=power_transform(doctor_test['Experience'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "As we see there are few rows which has qualifications extended till 17th column. Thus we will drop "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Regression Algorithms & Metrics\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor,AdaBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso,Ridge,ElasticNet\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxAccu=0\n",
    "maxRs=0\n",
    "for i in range(1,500):\n",
    "    x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.33,random_state=i)\n",
    "    lr=LinearRegression()\n",
    "    lr.fit(x_train,y_train)\n",
    "    lr_pred=lr.predict(x_test)\n",
    "    acc=r2_score(y_test,lr_pred)\n",
    "    if acc>maxAccu:\n",
    "        maxAccu=acc\n",
    "        maxRs=i\n",
    "print('Best R2 Score is : ', maxAccu, ' when Random state is : ',maxRs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.33,random_state=267)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Model List\n",
    "model_list=[LinearRegression(),SVR(),DecisionTreeRegressor(),KNeighborsRegressor(),RandomForestRegressor(),GradientBoostingRegressor(),AdaBoostRegressor(),Lasso(),Ridge(),ElasticNet(),XGBRegressor()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating For loop to print Training and Test accuracy score\n",
    "for m in model_list:\n",
    "    model=m\n",
    "    model.fit(x_train,y_train)\n",
    "    model_pred_train=model.predict(x_train)\n",
    "    model_pred=model.predict(x_test)\n",
    "    print('Training Accuracy for the model ',m,' is: ',r2_score(y_train,model_pred_train)*100)\n",
    "    print('Testing Accuracy for the model ',m,' is: ',r2_score(y_test,model_pred)*100)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "lr=LinearRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "lr_pred=lr.predict(x_test)\n",
    "testing_accu=r2_score(y_test,lr_pred)*100\n",
    "for k in range(2,10):\n",
    "    cv_score=cross_val_score(lr,x,y,cv=k)\n",
    "    cv_mean=cv_score.mean()*100\n",
    "    print(f'At crossfold {k} the CV score of is {cv_mean} and the accuracy for testing is {testing_accu} ')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validating RandomForestRegressor\n",
    "rfr=RandomForestRegressor()\n",
    "rfr.fit(x_train,y_train)\n",
    "rfr_pred=rfr.predict(x_test)\n",
    "testing_accu=r2_score(y_test,rfr_pred)*100\n",
    "for k in range(2,10):\n",
    "    cv_score=cross_val_score(rfr,x,y,cv=k)\n",
    "    cv_mean=cv_score.mean()*100\n",
    "    print(f'At crossfold {k} the CV score of is {cv_mean} and the accuracy for testing is {testing_accu} ')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validating GradientBoostingRegressor\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(x_train, y_train)\n",
    "gbr_pred=gbr.predict(x_test)\n",
    "testing_accu=r2_score(y_test,gbr_pred)*100\n",
    "for k in range(2,10):\n",
    "    cv_score=cross_val_score(gbr,x,y,cv=k)\n",
    "    cv_mean=cv_score.mean()*100\n",
    "    print(f'At crossfold {k} the CV score of is {cv_mean} and the accuracy for testing is {testing_accu} ')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validating Lasso\n",
    "ls=Lasso()\n",
    "ls.fit(x_train,y_train)\n",
    "ls_pred=ls.predict(x_test)\n",
    "testing_accu=r2_score(y_test,ls_pred)*100\n",
    "for k in range(2,10):\n",
    "    cv_score=cross_val_score(ls,x,y,cv=k)\n",
    "    cv_mean=cv_score.mean()*100\n",
    "    print(f'At crossfold {k} the CV score of is {cv_mean} and the accuracy for testing is {testing_accu} ')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validating Ridge\n",
    "rd=Ridge()\n",
    "rd.fit(x_train,y_train)\n",
    "rd_pred=rd.predict(x_test)\n",
    "testing_accu=r2_score(y_test,rd_pred)*100\n",
    "for k in range(2,10):\n",
    "    cv_score=cross_val_score(rd,x,y,cv=k)\n",
    "    cv_mean=cv_score.mean()*100\n",
    "    print(f'At crossfold {k} the CV score of is {cv_mean} and the accuracy for testing is {testing_accu} ')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Gridsearch CV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining parameters\n",
    "\n",
    "\n",
    "gr_param={'n_estimators':list(range(50,400,50)),'max_depth' : np.arange(2,8),'criterion':['mse','mae'],'max_features':['auto', 'sqrt', 'log2']}\n",
    "gcv= GridSearchCV(estimator=rfr,param_grid=gr_param,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Best Parameters\n",
    "\n",
    "gcv.fit(x_train,y_train)\n",
    "gcv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr1=RandomForestRegressor(criterion='mse',max_depth=7,max_features='sqrt',n_estimators=300)\n",
    "rfr1.fit(x_train,y_train)\n",
    "rfr1_pred=rfr1.predict(x_test)\n",
    "testing_accu=r2_score(y_test,rfr1_pred)*100\n",
    "for k in range(2,10):\n",
    "    cv_score=cross_val_score(rfr1,x,y,cv=k)\n",
    "    cv_mean=cv_score.mean()*100\n",
    "    print(f'At crossfold {k} the CV score of is {cv_mean} and the accuracy for testing is {testing_accu} ')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining parameters\n",
    "\n",
    "\n",
    "gbr_param={'n_estimators':list(range(50,400,50)),'max_depth' : np.arange(2,10),'learning_rate' :[0.01,0.1,0.2,0.3],'criterion':['friedman_mse', 'mse', 'mae'], 'max_features':['auto', 'sqrt', 'log2']}\n",
    "gcv_gbr= GridSearchCV(estimator=gbr,param_grid=gbr_param,scoring='r2',cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training final model with Gradient Boosting Regressor\n",
    "\n",
    "rfr1=RandomForestRegressor(criterion='mse',max_depth=7,max_features='sqrt',n_estimators=300)\n",
    "rfr1.fit(x_train,y_train)\n",
    "rfr1_pred=rfr1.predict(x_test)\n",
    "testing_accu=r2_score(y_test,rfr1_pred)*100\n",
    "\n",
    "cv_score=cross_val_score(rfr1,x,y,cv=5)\n",
    "cv_mean=cv_score.mean()*100\n",
    "print(f'The CV score of the model is {cv_mean} and the R2 Score for testing is {testing_accu} ')\n",
    "print('\\n')\n",
    "\n",
    "print('Mean Squared Error of the model is : ',mean_squared_error(y_test,rfr1_pred))\n",
    "print('Mean Absolute Error of the model is : ',mean_absolute_error(y_test,rfr1_pred))\n",
    "print('Root Mean Squared Error of the model is : ',np.sqrt(mean_squared_error(y_test,rfr1_pred)),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training final model with Gradient Boosting Regressor\n",
    "\n",
    "gbr1=GradientBoostingRegressor()\n",
    "gbr1.fit(x_train,y_train)\n",
    "gbr1_pred=gbr1.predict(x_test)\n",
    "testing_accu=r2_score(y_test,gbr1_pred)*100\n",
    "\n",
    "cv_score=cross_val_score(gbr1,x,y,cv=5)\n",
    "cv_mean=cv_score.mean()*100\n",
    "print(f'The CV score of the model is {cv_mean} and the R2 Score for testing is {testing_accu} ')\n",
    "print('\\n')\n",
    "\n",
    "print('Mean Squared Error of the model is : ',mean_squared_error(y_test,gbr1_pred))\n",
    "print('Mean Absolute Error of the model is : ',mean_absolute_error(y_test,gbr1_pred))\n",
    "print('Root Mean Squared Error of the model is : ',np.sqrt(mean_squared_error(y_test,gbr1_pred)),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will select Gradient Boosting Regressor as our final model as we get better results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename='doctor_con.pkl'\n",
    "pickle.dump(gbr1,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model=pickle.load(open('doctor_con.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=load_model.predict(doctor_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
